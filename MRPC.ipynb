{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of MRPC2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9W0HcPa9ajyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PRETRAINED_MODEL_DIR = 'My Drive/MLLU/pretrained_models/base'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCtIj9tEavTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_DIR = 'My Drive/MLLU/data'\n",
        "MODEL_DIR = 'My Drive/MLLU/model'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwiX2zYl7Nge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -qU t5 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bFKIs5fa125",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import functools\n",
        "import t5\n",
        "import torch\n",
        "import transformers\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "model = t5.models.HfPyTorchModel(\"t5-base\", MODEL_DIR, device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXzAz3S5a33a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "ds = tfds.load(\n",
        "    \"glue/mrpc\",\n",
        "    data_dir=DATA_DIR,\n",
        "    # Download data locally for preprocessing to avoid using GCS space.\n",
        "    download_and_prepare_kwargs={\"download_dir\": \"./downloads\"})\n",
        "print(\"A few raw validation examples...\")\n",
        "for ex in tfds.as_numpy(ds[\"validation\"].take(20)):\n",
        "  print(ex)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eL_a0bWa5u5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def label_preprocessor(ds):\n",
        "  \n",
        "  def to_inputs_and_targets(ex):\n",
        "    return {\n",
        "        \"inputs\": ex[\"input\"],\n",
        "        \"targets\": ex[\"output\"],\n",
        "        \"idx\": ex[\"idx\"]\n",
        "    }\n",
        "  ds_ = ds.map(to_inputs_and_targets,\n",
        "               num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  return ds_\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MES3WMuwa8Yx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mrpc_extract(ds):\n",
        "  def extract_io(ex):\n",
        "    return {\n",
        "        \"input\": \"mrpc sentence 1: \" + ex[\"sentence1\"] + \"  sentence 2:\" + ex[\"sentence2\"],\n",
        "        \"output\": \"unequal\" if ex[\"label\"] == 0 else \"equal\", \n",
        "        \"idx\": ex[\"idx\"]\n",
        "    }\n",
        "  return ds.map(extract_io, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "t5.data.TaskRegistry.remove(\"mrpc\")\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"mrpc\",\n",
        "    # A TfdsTask takes in a TFDS name instead of a tf.data.Dataset function.\n",
        "    t5.data.TfdsTask,\n",
        "    tfds_name=\"glue/mrpc:1.0.0\",\n",
        "    tfds_data_dir=DATA_DIR,\n",
        "    sentencepiece_model_path=t5.data.DEFAULT_SPM_PATH,\n",
        "    text_preprocessor=[mrpc_extract, label_preprocessor],\n",
        "    postprocess_fn=t5.data.postprocessors.lower_text,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy]\n",
        ")\n",
        "\n",
        "# Load and print a few examples.\n",
        "import tensorflow.compat.v1 as tf\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-6jXBXWbE6Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mrpc_task = t5.data.TaskRegistry.get(\"mrpc\")\n",
        "ds = mrpc_task.get_dataset(split=\"validation\", sequence_length={\"inputs\": 128, \"targets\": 4})\n",
        "print(\"A few preprocessed validation examples...\")\n",
        "max_ = 0\n",
        "for ex in tfds.as_numpy(ds):\n",
        "    print(ex)\n",
        "    max_=max(max_,len(ex[\"inputs\"]))\n",
        "print(max_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9WKrKOhbHAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate the pre-trained checkpoint, before further fine-tuning\n",
        "model.eval(\n",
        "    \"mrpc\",\n",
        "    sequence_length={\"inputs\": 128, \"targets\": 4},\n",
        "    batch_size=128,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbewkCzCbKvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Run 1000 steps of fine-tuning\n",
        "model.train(\n",
        "    mixture_or_task_name=\"mrpc\",\n",
        "    steps=2000,\n",
        "    save_steps=200,\n",
        "    sequence_length={\"inputs\": 128, \"targets\": 4},\n",
        "    split=\"train\",\n",
        "    batch_size=32,\n",
        "    optimizer=functools.partial(transformers.AdamW, lr=1e-4),\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIqsIL1vbPS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate after fine-tuning\n",
        "model.eval(\n",
        "    \"mrpc\",\n",
        "    checkpoint_steps=\"all\",\n",
        "    sequence_length={\"inputs\": 128, \"targets\": 4},\n",
        "    batch_size=128,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
