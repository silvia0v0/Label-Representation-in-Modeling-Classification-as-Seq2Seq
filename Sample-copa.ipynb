{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sample-copa.ipynb","provenance":[{"file_id":"1ranuznLc59YR0GK2AQNaYtBLFmyq8q1S","timestamp":1588657343611},{"file_id":"1J0-SvaBY0Z8gOs9_fGlC9rj4K_XFBQHJ","timestamp":1588212978272},{"file_id":"1WMoWSipIVW6kuTSSi6H1dDK6dONb0ngn","timestamp":1588041972928}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"72a9509f46cb4d12bd0a042e1f5c5315":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e9615d51419441cfacfb1daf5d4034fb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7f7f7670945d4d8b9959e5747b90aee8","IPY_MODEL_406d854d9f6941ae81905be3dee39587"]}},"e9615d51419441cfacfb1daf5d4034fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7f7f7670945d4d8b9959e5747b90aee8":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_636d6346a8d24399b27fde565dd52627","_dom_classes":[],"description":"Downloading: 100%","_model_name":"IntProgressModel","bar_style":"success","max":1199,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1199,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f345fb6c836146ca98d70691fa32a818"}},"406d854d9f6941ae81905be3dee39587":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3e41da4074ab4e399895873ac87d1b99","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.20k/1.20k [00:00&lt;00:00, 1.27kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_47c04dcc377149b5bd73d8d7798c5733"}},"636d6346a8d24399b27fde565dd52627":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f345fb6c836146ca98d70691fa32a818":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3e41da4074ab4e399895873ac87d1b99":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"47c04dcc377149b5bd73d8d7798c5733":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f8fae0d9ca1c477692e2b93ea1af0903":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fb415da6195642599a79dbe67e3d8cfc","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d0a5cb75e0ee44e5b07da52c187f64ac","IPY_MODEL_01b07105ce1f4ac0aeab97f625b304c3"]}},"fb415da6195642599a79dbe67e3d8cfc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d0a5cb75e0ee44e5b07da52c187f64ac":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4e81ce9807644d159cbaed7de09133e6","_dom_classes":[],"description":"Downloading: 100%","_model_name":"IntProgressModel","bar_style":"success","max":891691430,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":891691430,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9bafea52750c4f6a801fb3ba2120c37e"}},"01b07105ce1f4ac0aeab97f625b304c3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c8ebc752dec344ba87119d4ece1cdead","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 892M/892M [00:19&lt;00:00, 46.2MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9d7a5e6ea0094fc2a3db2aa32af59af3"}},"4e81ce9807644d159cbaed7de09133e6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9bafea52750c4f6a801fb3ba2120c37e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c8ebc752dec344ba87119d4ece1cdead":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9d7a5e6ea0094fc2a3db2aa32af59af3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"mgs3G4oy0Ic3","colab_type":"code","outputId":"bb5dc3e8-b4f2-4ad5-ff08-c745fdb024b6","executionInfo":{"status":"ok","timestamp":1588903989935,"user_tz":-480,"elapsed":76867,"user":{"displayName":"Silvia Chen","photoUrl":"","userId":"02156932270083514536"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9W0HcPa9ajyF","colab_type":"code","colab":{}},"source":["PRETRAINED_MODEL_DIR = 'drive/My Drive/MLLU/finalProject/pretrained_models/base'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FCtIj9tEavTn","colab_type":"code","colab":{}},"source":["DATA_DIR = 'drive/My Drive/MLLU/finalProject/data'\n","MODEL_DIR = 'drive/My Drive/MLLU/finalProject/model/copa'\n","PREDICTION_DIR = 'drive/My Drive/MLLU/finalProject/model/copa'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WwiX2zYl7Nge","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":323},"outputId":"2e78ad8c-3bcc-47c9-beb6-a5e2228d56d4","executionInfo":{"status":"ok","timestamp":1588904107462,"user_tz":-480,"elapsed":194357,"user":{"displayName":"Silvia Chen","photoUrl":"","userId":"02156932270083514536"}}},"source":["!pip install -qU t5 "],"execution_count":4,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 143kB 6.4MB/s \n","\u001b[K     |████████████████████████████████| 296kB 19.6MB/s \n","\u001b[K     |████████████████████████████████| 1.0MB 20.5MB/s \n","\u001b[K     |████████████████████████████████| 8.3MB 18.6MB/s \n","\u001b[K     |████████████████████████████████| 61kB 6.7MB/s \n","\u001b[K     |████████████████████████████████| 645kB 30.0MB/s \n","\u001b[K     |████████████████████████████████| 3.3MB 45.5MB/s \n","\u001b[K     |████████████████████████████████| 421.8MB 26kB/s \n","\u001b[K     |████████████████████████████████| 890kB 38.3MB/s \n","\u001b[K     |████████████████████████████████| 3.8MB 38.2MB/s \n","\u001b[K     |████████████████████████████████| 450kB 31.3MB/s \n","\u001b[K     |████████████████████████████████| 3.9MB 36.3MB/s \n","\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: tensorflow-probability 0.10.0rc0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.12.0, but you'll have six 1.14.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1bFKIs5fa125","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":115,"referenced_widgets":["72a9509f46cb4d12bd0a042e1f5c5315","e9615d51419441cfacfb1daf5d4034fb","7f7f7670945d4d8b9959e5747b90aee8","406d854d9f6941ae81905be3dee39587","636d6346a8d24399b27fde565dd52627","f345fb6c836146ca98d70691fa32a818","3e41da4074ab4e399895873ac87d1b99","47c04dcc377149b5bd73d8d7798c5733","f8fae0d9ca1c477692e2b93ea1af0903","fb415da6195642599a79dbe67e3d8cfc","d0a5cb75e0ee44e5b07da52c187f64ac","01b07105ce1f4ac0aeab97f625b304c3","4e81ce9807644d159cbaed7de09133e6","9bafea52750c4f6a801fb3ba2120c37e","c8ebc752dec344ba87119d4ece1cdead","9d7a5e6ea0094fc2a3db2aa32af59af3"]},"outputId":"953aed5e-0150-42e0-d29d-db11ad55c796","executionInfo":{"status":"ok","timestamp":1588904155346,"user_tz":-480,"elapsed":242233,"user":{"displayName":"Silvia Chen","photoUrl":"","userId":"02156932270083514536"}}},"source":["import functools\n","import t5\n","import torch\n","import transformers\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","else:\n","    device = torch.device(\"cpu\")\n","# model = t5.models.HfPyTorchModel(\"t5-small\", \"/tmp/hft5/\", device)\n","model = t5.models.HfPyTorchModel(\"t5-base\", MODEL_DIR, device)"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"72a9509f46cb4d12bd0a042e1f5c5315","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=1199, style=ProgressStyle(description_width…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f8fae0d9ca1c477692e2b93ea1af0903","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=891691430, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZXzAz3S5a33a","colab_type":"code","colab":{}},"source":["import tensorflow_datasets as tfds\n","sample = True\n","\n","def dataset_fn(split, shuffle_files=False):\n","  # train: 400   validation: 100    test: 500\n","  \n","  # We only have one file for each split.\n","  del shuffle_files\n","\n","  ds = tfds.load(\n","    \"super_glue/copa\",\n","    data_dir=DATA_DIR,\n","    # Download data locally for preprocessing to avoid using GCS space.\n","    download_and_prepare_kwargs={\"download_dir\": \"./downloads\"})\n","    #print(\"A few raw validation examples...\")\n","\n","  if split == 'validation':\n","    if sample:\n","      ds = ds['validation'].take(50)\n","    else:\n","      ds = ds['validation']\n","      \n","  elif split == \"train\":\n","    if sample:\n","      ds = ds['train'].take(200)\n","    else:\n","      ds = ds['train']\n","  # else:\n","  #   ds = ds['test']\n","\n","  return ds\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3eL_a0bWa5u5","colab_type":"code","colab":{}},"source":["def label_preprocessor(ds):\n","  \n","  def normalize_text(text):\n","    \"\"\"Lowercase and remove quotes from a TensorFlow string.\"\"\"\n","    text = tf.strings.lower(text)\n","    text = tf.strings.regex_replace(text,\"'(.*)'\", r\"\\1\")\n","    return text\n","  \n","  def to_inputs_and_targets(ex):\n","    return {\n","        \"inputs\": \"copa choice1: \"+ex[\"choice1\"]+\"  choice2: \"+\n","                  ex[\"choice2\"]+\"  premise: \"+ex[\"premise\"]+\"  question: \"+ex[\"question\"],\n","        \"targets\":\"i\" if ex[\"label\"] == 0 else \"eutelelwld\",    # change labels\n","        \"idx\": ex[\"idx\"]\n","    }\n","\n","  return ds.map(to_inputs_and_targets,\n","               num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MES3WMuwa8Yx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":547},"outputId":"b52b0ca1-8008-4203-885d-8fbbc2a2b8a1","executionInfo":{"status":"ok","timestamp":1588904161594,"user_tz":-480,"elapsed":248454,"user":{"displayName":"Silvia Chen","photoUrl":"","userId":"02156932270083514536"}}},"source":["t5.data.TaskRegistry.remove(\"copa\")\n","t5.data.TaskRegistry.add(\n","    \"copa\",\n","    # A TfdsTask takes in a TFDS name instead of a tf.data.Dataset function.\n","    dataset_fn=dataset_fn,\n","    splits=[\"train\", \"validation\"],\n","    sentencepiece_model_path=t5.data.DEFAULT_SPM_PATH,\n","    text_preprocessor=[label_preprocessor],\n","    postprocess_fn=t5.data.postprocessors.lower_text,\n","    metric_fns=[t5.evaluation.metrics.accuracy]\n",")\n","\n","# Load and print a few examples.\n","# check seq_len\n","import tensorflow.compat.v1 as tf\n","\n","cola_task = t5.data.TaskRegistry.get(\"copa\")\n","ds = cola_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 64, \"targets\":16})\n","print(\"A few preprocessed train examples...\")\n","seq_len_max = 0\n","input_len_max = 0\n","for ex in tfds.as_numpy(ds):\n","  seq_len_max = max(seq_len_max, ex['targets'].shape[0])\n","  input_len_max = max(input_len_max, ex['inputs'].shape[0])\n","print('seq_len_max:', seq_len_max)\n","print('input_len_max:', input_len_max)\n","for ex in tfds.as_numpy(ds.take(5)):\n","  print(ex)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["INFO:absl:Load dataset info from drive/My Drive/MLLU/finalProject/data/super_glue/copa/1.0.2\n","INFO:absl:Reusing dataset super_glue (drive/My Drive/MLLU/finalProject/data/super_glue/copa/1.0.2)\n","INFO:absl:Constructing tf.data.Dataset for split None, from drive/My Drive/MLLU/finalProject/data/super_glue/copa/1.0.2\n"],"name":"stderr"},{"output_type":"stream","text":["A few preprocessed train examples...\n","seq_len_max: 9\n","input_len_max: 52\n","{'inputs_plaintext': b\"copa choice1: The ship crashed into the pier.  choice2: The ship's debris sunk in the sea.  premise: The navy bombed the ship.  question: effect\", 'inputs': array([ 7326,     9,  1160,   536,    10,    37,  4383, 24679,   139,\n","           8,     3,  8343,     5,  1160,   357,    10,    37,  4383,\n","          31,     7, 12544,     3,     7,  6513,    16,     8,  2805,\n","           5,     3, 17398,    10,    37, 23118,  6417,    15,    26,\n","           8,  4383,     5,   822,    10,  1504,     1]), 'targets_plaintext': b'eutelelwld', 'targets': array([   3,   15,   76, 1931,   40,  210,   40,   26,    1]), 'idx': 145}\n","{'inputs_plaintext': b'copa choice1: She opened her parachute.  choice2: She jumped out of the plane.  premise: The skydiver glided safely to the ground.  question: cause', 'inputs': array([ 7326,     9,  1160,   536,    10,   451,  2946,   160,   260,\n","        1836,  2810,     5,  1160,   357,    10,   451,     3, 16287,\n","          91,    13,     8,  6112,     5,     3, 17398,    10,    37,\n","        5796,  8481,    49, 26537,    26,  7794,    12,     8,  1591,\n","           5,   822,    10,  1137,     1]), 'targets_plaintext': b'i', 'targets': array([ 3, 23,  1]), 'idx': 25}\n","{'inputs_plaintext': b'copa choice1: He went camping in the woods.  choice2: He fell asleep on his couch.  premise: The man was bitten by mosquitoes.  question: cause', 'inputs': array([ 7326,     9,  1160,   536,    10,   216,   877,  8515,    16,\n","           8,  1679,     7,     5,  1160,   357,    10,   216,  4728,\n","       17915,    30,   112,  6452,     5,     3, 17398,    10,    37,\n","         388,    47,     3, 26040,    57, 22315,    15,     7,     5,\n","         822,    10,  1137,     1]), 'targets_plaintext': b'i', 'targets': array([ 3, 23,  1]), 'idx': 316}\n","{'inputs_plaintext': b'copa choice1: The woman kissed him.  choice2: The woman made him blush.  premise: The man had lipstick on his cheek.  question: cause', 'inputs': array([ 7326,     9,  1160,   536,    10,    37,  2335, 17387,    15,\n","          26,   376,     5,  1160,   357,    10,    37,  2335,   263,\n","         376, 27323,     5,     3, 17398,    10,    37,   388,   141,\n","       27406,    30,   112, 18312,     5,   822,    10,  1137,     1]), 'targets_plaintext': b'i', 'targets': array([ 3, 23,  1]), 'idx': 200}\n","{'inputs_plaintext': b'copa choice1: The wood became smooth.  choice2: The wood became sticky.  premise: I rubbed sandpaper on the wood.  question: effect', 'inputs': array([ 7326,     9,  1160,   536,    10,    37,  1679,  1632,  3050,\n","           5,  1160,   357,    10,    37,  1679,  1632, 19885,     5,\n","           3, 17398,    10,    27,     3,    52, 17344,     3,     7,\n","         232, 19587,    30,     8,  1679,     5,   822,    10,  1504,\n","           1]), 'targets_plaintext': b'i', 'targets': array([ 3, 23,  1]), 'idx': 58}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G-6jXBXWbE6Y","colab_type":"code","colab":{}},"source":["# mrpc_task = t5.data.TaskRegistry.get(\"copa\")\n","# ds = mrpc_task.get_dataset(split='validation', sequence_length={\"inputs\": 64, \"targets\": 4})\n","# print(\"A few preprocessed validation examples...\")\n","# max_ = 0\n","# count = 0\n","# for ex in tfds.as_numpy(ds.take(20)):\n","#     print(ex['inputs_plaintext'])\n","#     count += 1\n","#     max_=max(max_,len(ex[\"targets\"]))\n","# print(max_)\n","# print(count)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_9WKrKOhbHAJ","colab_type":"code","outputId":"a8a97eee-330f-4b5c-80b3-0cd50264c8ce","executionInfo":{"status":"ok","timestamp":1588904164057,"user_tz":-480,"elapsed":250896,"user":{"displayName":"Silvia Chen","photoUrl":"","userId":"02156932270083514536"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["# Evaluate the pre-trained checkpoint, before further fine-tuning\n","model.eval(\n","    \"copa\",\n","    sequence_length={\"inputs\": 64, \"targets\": 16},\n","    batch_size=128,\n",")"],"execution_count":10,"outputs":[{"output_type":"stream","text":["INFO:absl:Load dataset info from drive/My Drive/MLLU/finalProject/data/super_glue/copa/1.0.2\n","INFO:absl:Reusing dataset super_glue (drive/My Drive/MLLU/finalProject/data/super_glue/copa/1.0.2)\n","INFO:absl:Constructing tf.data.Dataset for split None, from drive/My Drive/MLLU/finalProject/data/super_glue/copa/1.0.2\n","INFO:absl:eval/copa/accuracy at step 0: 0.000\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"UbewkCzCbKvb","colab_type":"code","outputId":"69650fba-a4b5-4808-9493-3105d0504e0c","executionInfo":{"status":"error","timestamp":1588904168770,"user_tz":-480,"elapsed":255598,"user":{"displayName":"Silvia Chen","photoUrl":"","userId":"02156932270083514536"}},"colab":{"base_uri":"https://localhost:8080/","height":422}},"source":["# Run 1000 steps of fine-tuning\n","model.train(\n","    mixture_or_task_name=\"copa\",\n","    steps=2000,\n","    save_steps=200,\n","    sequence_length={\"inputs\": 64, \"targets\": 16},\n","    split=\"train\",\n","    batch_size=32,\n","    optimizer=functools.partial(transformers.AdamW, lr=1e-4),\n",")"],"execution_count":11,"outputs":[{"output_type":"stream","text":["INFO:absl:Load dataset info from drive/My Drive/MLLU/finalProject/data/super_glue/copa/1.0.2\n","INFO:absl:Reusing dataset super_glue (drive/My Drive/MLLU/finalProject/data/super_glue/copa/1.0.2)\n","INFO:absl:Constructing tf.data.Dataset for split None, from drive/My Drive/MLLU/finalProject/data/super_glue/copa/1.0.2\n","INFO:absl:Saving checkpoint for step 0\n"],"name":"stderr"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-0de8484d7dd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/t5/models/hf_model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, mixture_or_task_name, steps, save_steps, sequence_length, split, batch_size, optimizer, learning_rate_scheduler)\u001b[0m\n\u001b[1;32m    326\u001b[0m           \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inputs_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m           \u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"targets_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m           \u001b[0mlm_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"targets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m       )\n\u001b[1;32m    330\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"]}]},{"cell_type":"code","metadata":{"id":"JIqsIL1vbPS0","colab_type":"code","colab":{}},"source":["# Evaluate after fine-tuning\n","model.eval(\n","    \"copa\",\n","    checkpoint_steps=\"all\",\n","    sequence_length={\"inputs\": 64, \"targets\": 16},\n","    batch_size=128,\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4XgyHDb8HcYu","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}