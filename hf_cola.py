# -*- coding: utf-8 -*-
"""hf-cola.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bOPS2191jGvVtN8J0HdI1ANR1CGSQx-c
"""

#from google.colab import drive
#drive.mount('/content/drive')


import functools
import t5
import torch
import transformers
import tensorflow_datasets as tfds
import tensorflow.compat.v1 as tf
import random
import string


DATA_DIR = 'drive/My Drive/MLLU/finalProject/glue_data'
MODEL_DIR = 'drive/My Drive/MLLU/finalProject/model'
PREDICTION_DIR = 'drive/My Drive/MLLU/finalProject/model/cola'


if torch.cuda.is_available():
    device = torch.device("cuda")
else:
    device = torch.device("cpu")
    
# model = t5.models.HfPyTorchModel("t5-base", "/tmp/hft5/", device)
model = t5.models.HfPyTorchModel("t5-base", MODEL_DIR, device)


ds = tfds.load(
    "glue/cola",
    data_dir=DATA_DIR,
    # Download data locally for preprocessing to avoid using GCS space.
    download_and_prepare_kwargs={"download_dir": "./downloads"})

print("A few raw validation examples...")
for ex in tfds.as_numpy(ds["validation"].take(2)):
  print(ex)

possible_labels = [0,1]
 
def randomString():
   stringLength = random.randint(1,15)
   """Generate a random string of random length """
   letters = string.ascii_lowercase
   return ''.join(random.choice(letters) for i in range(stringLength))
 
label_map = {}
label_set = set()

for i in range(len(possible_labels)):
   label_map[possible_labels[i]] = randomString()
   label_set.add(label_map[possible_labels[i]])
 
assert(len(possible_labels) == len(label_set))
 
print(label_map)

"""Now, we write a preprocess function to convert the examples in the `tf.data.Dataset` into a text-to-text format, with both `inputs` and `targets` fields. The preprocessor also normalizes the text by lowercasing it and removing quotes since the answers are sometimes formatted in odd ways. Finally, we prepend 'trivia question:' to the inputs so that the model knows what task it's trying to solve."""

def label_preprocessor(ds):

  def normalize_text(text):
    """Lowercase and remove quotes from a TensorFlow string."""
    text = tf.strings.lower(text)
    text = tf.strings.regex_replace(text,"'(.*)'", r"\1")
    return text
  
  def to_inputs_and_targets(ex):
    return {
        "inputs": normalize_text(ex["input"]),
        "targets": ex["output"],
        "idx": ex["idx"]
    }
  ds_ = ds.map(to_inputs_and_targets,
               num_parallel_calls=tf.data.experimental.AUTOTUNE)
  return ds_

def cola_extract(ds):
  def extract_io(ex):
    return {
        "input": "cola sentence: "+ex["sentence"],
        "output": "cold" if ex["label"] == 0 else "hot",    # change labels
        "idx": ex["idx"]
    }
  return ds.map(extract_io, num_parallel_calls=tf.data.experimental.AUTOTUNE)

t5.data.TaskRegistry.remove("cola_random_label")
t5.data.TaskRegistry.add(
    "cola_random_label",
    # A TfdsTask takes in a TFDS name instead of a tf.data.Dataset function.
    t5.data.TfdsTask,
    tfds_name="glue/cola:1.0.0",
    tfds_data_dir=DATA_DIR,
    sentencepiece_model_path=t5.data.DEFAULT_SPM_PATH,
    text_preprocessor=[cola_extract, label_preprocessor],
    postprocess_fn=t5.data.postprocessors.lower_text,
    metric_fns=[t5.evaluation.metrics.matthews_corrcoef]
)

# Load and print a few examples.

cola_task = t5.data.TaskRegistry.get("cola_random_label")
ds = cola_task.get_dataset(split="train", sequence_length={"inputs": 64, "targets": 4})
print("A few preprocessed train examples...")
for ex in tfds.as_numpy(ds.take(5)):
  print(ex)

# Evaluate on the original task
print('Evaluate on the original task...')
model.eval(
    "glue_cola_v002",
    sequence_length={"inputs": 64, "targets": 4},
    batch_size=128,
)

# Evaluate the pre-trained checkpoint, before further fine-tuning
print('Evaluate on the current task...')
model.eval(
    "cola_random_label",
    sequence_length={"inputs": 64, "targets": 4},
    batch_size=128,
)

# Run 2000 steps of fine-tuning
print('Start training...')
model.train(
    mixture_or_task_name="cola_random_label",
    steps=2000,
    save_steps=200,
    sequence_length={"inputs": 64, "targets": 4},
    split="train",
    batch_size=32,
    optimizer=functools.partial(transformers.AdamW, lr=1e-4),
)

# Evaluate after fine-tuning
print('Evaluating the current task after fine-tuning...')
model.eval(
    "cola_random_label",
    checkpoint_steps="all",
    sequence_length={"inputs": 64, "targets": 4},
    batch_size=32,
)

# Generate some predictions
print('Generate some predictions...')
inputs = [
    "cola sentence: This is a totally valid sentence.",
    "cola sentence: A doggy detail was walking famously.",
    "cola sentence: The weather is fine today.",
    "cola sentence: She ran outside of the window largely.",
]
model.predict(
    inputs,
    sequence_length={"inputs": 64},
    batch_size=2,
    output_file=PREDICTION_DIR + "/example_predictions.txt",
)

model.load_latest_checkpoint()

# Use model.predict to predict the validation set
print('Predicting the validation set...')
inputs_all = []
targets_all = []
except_num = 0
mrpc_task = t5.data.TaskRegistry.get("glue_cola_v002")
ds = mrpc_task.get_dataset(split="validation", sequence_length={"inputs": 64, "targets": 4})
for ex in tfds.as_numpy(ds):
  try:
    inputs_all.append(ex["inputs_plaintext"].decode("ascii"))
    targets_all.append(ex["targets_plaintext"].decode("ascii"))
  except:
    except_num += 1
    # print('EXCEPT!!\n!!!\n'+str(ex["inputs_plaintext"]) + '\n'+str(ex["targets_plaintext"])+'!!!\n!!!')
    continue
model.predict(
    inputs_all,
    sequence_length={"inputs": 64,'targets': 4},
    batch_size=128,
    output_file=PREDICTION_DIR + "/val_predictions.txt",
)

f = open(PREDICTION_DIR + "/val_predictions.txt", "r") 
lines = f.readlines()
predicts_all = [line.rstrip() for line in lines]
#print('except:', except_num)
#print('without exception:', len(predicts_all))
#print('len targets:', len(targets_all))
#print('predicts_all:', predicts_all)
#print('targets_all:', targets_all)

score = t5.evaluation.metrics.matthews_corrcoef(targets_all, predicts_all)
print('prediction score:',score)

