{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hf-copa.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c23d8a6daee34b47b59f6ab22d864d70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a94e6ce62a384c09ba0ecb4360bec426",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_91d92a4ef2564f81b904ca2b38ec92dd",
              "IPY_MODEL_228685d22c3246e38ad7d7e4738832bf"
            ]
          }
        },
        "a94e6ce62a384c09ba0ecb4360bec426": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91d92a4ef2564f81b904ca2b38ec92dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6788ab2831994872a3c9b521793ab9dc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1199,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1199,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7f2ac2dcbf9a4beea039b846edf6fccd"
          }
        },
        "228685d22c3246e38ad7d7e4738832bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_077d1c3175cf401fab384a575c82fb45",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.20k/1.20k [00:02&lt;00:00, 428B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ce32d62f7a2c4d5281d69c28caf4e6b2"
          }
        },
        "6788ab2831994872a3c9b521793ab9dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7f2ac2dcbf9a4beea039b846edf6fccd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "077d1c3175cf401fab384a575c82fb45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ce32d62f7a2c4d5281d69c28caf4e6b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c0895d8a0c1e4215ba4ce4b3653bc664": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5b5841c9e3a746bd9041253a49f71958",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b623c7db7cdb472e8f3d3210d77b9575",
              "IPY_MODEL_b4a8da287bd84cdb8a35f66919ced4eb"
            ]
          }
        },
        "5b5841c9e3a746bd9041253a49f71958": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b623c7db7cdb472e8f3d3210d77b9575": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_49eaba96f9f548a79c97a04ad4337aee",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 891691430,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 891691430,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ffcd81096b244d4fa1ec3dbcef3f6b5b"
          }
        },
        "b4a8da287bd84cdb8a35f66919ced4eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_19a0202d51484d589ca034520c602251",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 892M/892M [01:21&lt;00:00, 10.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4cab40845f7b4a2d9ceaa7ad45a92fd4"
          }
        },
        "49eaba96f9f548a79c97a04ad4337aee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ffcd81096b244d4fa1ec3dbcef3f6b5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "19a0202d51484d589ca034520c602251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4cab40845f7b4a2d9ceaa7ad45a92fd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgs3G4oy0Ic3",
        "colab_type": "code",
        "outputId": "4c3e07a3-79ff-4803-87a4-f4589437e68a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8rtggTeG0Ex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_DIR = 'drive/My Drive/MLLU/finalProject/data'\n",
        "MODEL_DIR = 'drive/My Drive/MLLU/finalProject/model/copa'\n",
        "PREDICTION_DIR = 'drive/My Drive/MLLU/finalProject/model/copa'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwiX2zYl7Nge",
        "colab_type": "code",
        "outputId": "5e1b12f0-6068-48d4-82ce-a89f25259725",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "!pip install -qU t5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |██▎                             | 10kB 29.0MB/s eta 0:00:01\r\u001b[K     |████▋                           | 20kB 33.6MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 30kB 36.1MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 40kB 27.9MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 51kB 15.1MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 61kB 12.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 71kB 11.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 81kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 92kB 11.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 102kB 12.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 112kB 12.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 122kB 12.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 133kB 12.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 143kB 12.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3MB 20.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0MB 36.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 645kB 45.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.3MB 36.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 9.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 296kB 55.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 53.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8MB 50.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 421.8MB 29kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.9MB 48.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 450kB 58.8MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0rc0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.12.0, but you'll have six 1.14.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wr_D5_Vx7aUd",
        "colab_type": "code",
        "outputId": "45314524-6254-41e1-d20a-b78fe0ef8f62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132,
          "referenced_widgets": [
            "c23d8a6daee34b47b59f6ab22d864d70",
            "a94e6ce62a384c09ba0ecb4360bec426",
            "91d92a4ef2564f81b904ca2b38ec92dd",
            "228685d22c3246e38ad7d7e4738832bf",
            "6788ab2831994872a3c9b521793ab9dc",
            "7f2ac2dcbf9a4beea039b846edf6fccd",
            "077d1c3175cf401fab384a575c82fb45",
            "ce32d62f7a2c4d5281d69c28caf4e6b2",
            "c0895d8a0c1e4215ba4ce4b3653bc664",
            "5b5841c9e3a746bd9041253a49f71958",
            "b623c7db7cdb472e8f3d3210d77b9575",
            "b4a8da287bd84cdb8a35f66919ced4eb",
            "49eaba96f9f548a79c97a04ad4337aee",
            "ffcd81096b244d4fa1ec3dbcef3f6b5b",
            "19a0202d51484d589ca034520c602251",
            "4cab40845f7b4a2d9ceaa7ad45a92fd4"
          ]
        }
      },
      "source": [
        "import functools\n",
        "import t5\n",
        "import torch\n",
        "import transformers\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "# model = t5.models.HfPyTorchModel(\"t5-base\", \"/tmp/hft5/\", device)\n",
        "model = t5.models.HfPyTorchModel(\"t5-base\", MODEL_DIR, device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c23d8a6daee34b47b59f6ab22d864d70",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1199.0, style=ProgressStyle(description…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0895d8a0c1e4215ba4ce4b3653bc664",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=891691430.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Loading from drive/My Drive/MLLU/finalProject/model/copa/model-0.checkpoint\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuZ847qKAlAn",
        "colab_type": "code",
        "outputId": "a6b15d31-d426-4dfa-b040-afe4b3b6be5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "ds = tfds.load(\n",
        "    \"super_glue/copa\",\n",
        "    data_dir=DATA_DIR,\n",
        "    shuffle_files=True,\n",
        "    # Download data locally for preprocessing to avoid using GCS space.\n",
        "    download_and_prepare_kwargs={\"download_dir\": \"./downloads\"})\n",
        "ds[\"train\"] = ds[\"train\"].take(100)\n",
        "print(\"A few raw validation examples...\")\n",
        "print(ds)\n",
        "for ex in tfds.as_numpy(ds[\"train\"].take(11)):\n",
        "  print(ex)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Load dataset info from drive/My Drive/MLLU/finalProject/data/super_glue/copa/1.0.2\n",
            "INFO:absl:Reusing dataset super_glue (drive/My Drive/MLLU/finalProject/data/super_glue/copa/1.0.2)\n",
            "INFO:absl:Constructing tf.data.Dataset for split None, from drive/My Drive/MLLU/finalProject/data/super_glue/copa/1.0.2\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "A few raw validation examples...\n",
            "{'test': <_OptionsDataset shapes: {choice1: (), choice2: (), idx: (), label: (), premise: (), question: ()}, types: {choice1: tf.string, choice2: tf.string, idx: tf.int32, label: tf.int64, premise: tf.string, question: tf.string}>, 'train': <TakeDataset shapes: {choice1: (), choice2: (), idx: (), label: (), premise: (), question: ()}, types: {choice1: tf.string, choice2: tf.string, idx: tf.int32, label: tf.int64, premise: tf.string, question: tf.string}>, 'validation': <_OptionsDataset shapes: {choice1: (), choice2: (), idx: (), label: (), premise: (), question: ()}, types: {choice1: tf.string, choice2: tf.string, idx: tf.int32, label: tf.int64, premise: tf.string, question: tf.string}>}\n",
            "{'choice1': b'I was hunting for a new apartment.', 'choice2': b'I was moving out of my apartment.', 'idx': 386, 'label': 1, 'premise': b'I packed up my belongings.', 'question': b'cause'}\n",
            "{'choice1': b'The lid on the mailbox broke.', 'choice2': b'I went on vacation for two weeks.', 'idx': 266, 'label': 1, 'premise': b'My mailbox was overflowing with letters.', 'question': b'cause'}\n",
            "{'choice1': b'The paper sliced apart.', 'choice2': b'The paper crinkled.', 'idx': 230, 'label': 0, 'premise': b'The girl applied the scissors to the paper.', 'question': b'effect'}\n",
            "{'choice1': b'The woman glanced at her watch.', 'choice2': b'The woman took her sweater off.', 'idx': 307, 'label': 1, 'premise': b'The sun emerged from the clouds.', 'question': b'effect'}\n",
            "{'choice1': b'I clamped my hand over my nose.', 'choice2': b'I put the rubber gloves on.', 'idx': 354, 'label': 0, 'premise': b'The putrid odor filled the room.', 'question': b'effect'}\n",
            "{'choice1': b'She went to see his new film.', 'choice2': b'She asked him for his autograph.', 'idx': 247, 'label': 1, 'premise': b'The girl met her favorite actor.', 'question': b'effect'}\n",
            "{'choice1': b'It was inflated.', 'choice2': b'There was a hole in it.', 'idx': 243, 'label': 1, 'premise': b'Air leaked out of the beach ball.', 'question': b'cause'}\n",
            "{'choice1': b'She decided to sue her employer.', 'choice2': b'She decided to run for office.', 'idx': 39, 'label': 0, 'premise': b'The woman hired a lawyer.', 'question': b'cause'}\n",
            "{'choice1': b'I took it apart.', 'choice2': b'I replaced the batteries.', 'idx': 135, 'label': 1, 'premise': b'The flashlight was dead.', 'question': b'effect'}\n",
            "{'choice1': b'He refused to talk to her.', 'choice2': b'He avoided making eye contact with her.', 'idx': 179, 'label': 1, 'premise': b'The mother suspected that her son was lying.', 'question': b'cause'}\n",
            "{'choice1': b'The gun recoiled.', 'choice2': b'The gun went off.', 'idx': 55, 'label': 1, 'premise': b'The police officer dropped the gun.', 'question': b'effect'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCv5z1ctHQIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "possible_labels = [0,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nszP1p3MHQ17",
        "colab_type": "code",
        "outputId": "6c8d1f0d-bae1-4a9e-de0f-f9d7fe3985aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import random\n",
        "import string\n",
        " \n",
        "def randomString():\n",
        "   stringLength = random.randint(1,15)\n",
        "   \"\"\"Generate a random string of random length \"\"\"\n",
        "   letters = string.ascii_lowercase\n",
        "   return ''.join(random.choice(letters) for i in range(stringLength))\n",
        " \n",
        "label_map = {}\n",
        "label_set = set()\n",
        "for i in range(len(possible_labels)):\n",
        "   label_map[possible_labels[i]] = randomString()\n",
        "   label_set.add(label_map[possible_labels[i]])\n",
        " \n",
        "assert(len(possible_labels) == len(label_set))\n",
        " \n",
        "print(label_map)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 'kprspoiyastmmn', 1: 'pbflvzqppto'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MCUYT7JmX9Tj"
      },
      "source": [
        "Now, we write a preprocess function to convert the examples in the `tf.data.Dataset` into a text-to-text format, with both `inputs` and `targets` fields. The preprocessor also normalizes the text by lowercasing it and removing quotes since the answers are sometimes formatted in odd ways. Finally, we prepend 'trivia question:' to the inputs so that the model knows what task it's trying to solve."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-akQW_KHYlJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def label_preprocessor(ds):\n",
        "\n",
        "  def normalize_text(text):\n",
        "    \"\"\"Lowercase and remove quotes from a TensorFlow string.\"\"\"\n",
        "    text = tf.strings.lower(text)\n",
        "    text = tf.strings.regex_replace(text,\"'(.*)'\", r\"\\1\")\n",
        "    return text\n",
        "  \n",
        "  def to_inputs_and_targets(ex):\n",
        "    return {\n",
        "        \"inputs\": normalize_text(ex[\"input\"]),\n",
        "        \"targets\": ex[\"output\"],\n",
        "        \"idx\": ex[\"idx\"]\n",
        "    }\n",
        "  ds_ = ds.map(to_inputs_and_targets,\n",
        "               num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  return ds_\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6rU32DjyeLuL",
        "outputId": "0b8da62b-e168-4889-d264-aa1fa563e3c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "def copa_extract(ds):\n",
        "  def extract_io(ex):\n",
        "    return {\n",
        "        \"input\": \"copa choice1: \"+ex[\"choice1\"]+\"  choice2: \"+\n",
        "                  ex[\"choice2\"]+\"  premise: \"+ex[\"premise\"]+\"  question: \"+ex[\"question\"],\n",
        "        \"output\": \"cold\" if ex[\"label\"] == 0 else \"hot\",    # change labels\n",
        "        \"idx\": ex[\"idx\"]\n",
        "    }\n",
        "  return ds.map(extract_io, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "t5.data.TaskRegistry.remove(\"copa_new\")\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"copa_new\",\n",
        "    # A TfdsTask takes in a TFDS name instead of a tf.data.Dataset function.\n",
        "    t5.data.TfdsTask,\n",
        "    tfds_name=\"super_glue/copa:1.0.2\",\n",
        "    tfds_data_dir=DATA_DIR,\n",
        "    sentencepiece_model_path=t5.data.DEFAULT_SPM_PATH,\n",
        "    text_preprocessor=[copa_extract, label_preprocessor],\n",
        "    postprocess_fn=t5.data.postprocessors.lower_text,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy]\n",
        ")\n",
        "\n",
        "# Load and print a few examples.\n",
        "import tensorflow.compat.v1 as tf\n",
        "cola_task = t5.data.TaskRegistry.get(\"copa_new\")\n",
        "ds = cola_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 64, \"targets\":2})\n",
        "print(\"A few preprocessed train examples...\")\n",
        "seq_len_max = 0\n",
        "input_len_max = 0\n",
        "for ex in tfds.as_numpy(ds):\n",
        "  seq_len_max = max(seq_len_max, ex['targets'].shape[0])\n",
        "  input_len_max = max(input_len_max, ex['inputs'].shape[0])\n",
        "print('seq_len_max:', seq_len_max)\n",
        "print('input_len_max:', input_len_max)\n",
        "for ex in tfds.as_numpy(ds.take(5)):\n",
        "  print(ex)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Load dataset info from drive/My Drive/MLLU/finalProject/data/super_glue/copa/1.0.2\n",
            "INFO:absl:Reusing dataset super_glue (drive/My Drive/MLLU/finalProject/data/super_glue/copa/1.0.2)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train, from drive/My Drive/MLLU/finalProject/data/super_glue/copa/1.0.2\n",
            "INFO:absl:Load dataset info from drive/My Drive/MLLU/finalProject/data/super_glue/copa/1.0.2\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "A few preprocessed train examples...\n",
            "seq_len_max: 2\n",
            "input_len_max: 55\n",
            "{'inputs_plaintext': b'copa choice1: i forgot to eat breakfast.  choice2: i was full from breakfast.  premise: my stomach growled.  question: cause', 'inputs': array([ 7326,     9,  1160,   536,    10,     3,    23, 15687,    12,\n",
            "           3,  1544,  3688,     5,  1160,   357,    10,     3,    23,\n",
            "          47,   423,    45,  3688,     5,     3, 17398,    10,    82,\n",
            "        9883,  1604,  1361,     5,   822,    10,  1137,     1]), 'targets_plaintext': b'cold', 'targets': array([2107,    1]), 'idx': 61}\n",
            "{'inputs_plaintext': b'copa choice1: he got over it easily.  choice2: he refused to talk about it.  premise: the man went into denial about the tragedy.  question: effect', 'inputs': array([ 7326,     9,  1160,   536,    10,     3,    88,   530,   147,\n",
            "          34,  1153,     5,  1160,   357,    10,     3,    88, 12191,\n",
            "          12,  1350,    81,    34,     5,     3, 17398,    10,     8,\n",
            "         388,   877,   139,    20,  7419,    81,     8, 18914,     5,\n",
            "         822,    10,  1504,     1]), 'targets_plaintext': b'hot', 'targets': array([1312,    1]), 'idx': 373}\n",
            "{'inputs_plaintext': b'copa choice1: she wanted attention.  choice2: she felt shy.  premise: the woman exaggerated the details of the story.  question: cause', 'inputs': array([ 7326,     9,  1160,   536,    10,   255,  1114,  1388,     5,\n",
            "        1160,   357,    10,   255,  1800, 17837,     5,     3, 17398,\n",
            "          10,     8,  2335,  1215,     9,  6938,   920,     8,  1030,\n",
            "          13,     8,   733,     5,   822,    10,  1137,     1]), 'targets_plaintext': b'cold', 'targets': array([2107,    1]), 'idx': 371}\n",
            "{'inputs_plaintext': b'copa choice1: i remained quiet.  choice2: i told a joke.  premise: i wanted to lighten the mood of the conversation.  question: effect', 'inputs': array([ 7326,     9,  1160,   536,    10,     3,    23,     3,  7361,\n",
            "        4354,     5,  1160,   357,    10,     3,    23,  1219,     3,\n",
            "           9, 10802,     5,     3, 17398,    10,     3,    23,  1114,\n",
            "          12,   659,    35,     8,  6526,    13,     8,  3634,     5,\n",
            "         822,    10,  1504,     1]), 'targets_plaintext': b'hot', 'targets': array([1312,    1]), 'idx': 235}\n",
            "{'inputs_plaintext': b'copa choice1: the sun was rising.  choice2: the grass was cut.  premise: my body cast a shadow over the grass.  question: cause', 'inputs': array([ 7326,     9,  1160,   536,    10,     8,  1997,    47,  6937,\n",
            "           5,  1160,   357,    10,     8,  5956,    47,  1340,     5,\n",
            "           3, 17398,    10,    82,   643,  4061,     3,     9,  8552,\n",
            "         147,     8,  5956,     5,   822,    10,  1137,     1]), 'targets_plaintext': b'cold', 'targets': array([2107,    1]), 'idx': 0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcCiOQxLWAlK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Evaluate the pre-trained checkpoint, before further fine-tuning\n",
        "# model.eval(\n",
        "#     \"super_glue_copa_v102\",\n",
        "#     sequence_length={\"inputs\": 64, \"targets\": 4},\n",
        "#     batch_size=128,\n",
        "# )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsZBYzrsLa0z",
        "colab_type": "code",
        "outputId": "59bb1923-f49f-4ed3-d7e9-66f2e054b069",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Evaluate the pre-trained checkpoint, before further fine-tuning\n",
        "model.eval(\n",
        "    \"copa_new\",\n",
        "    sequence_length={\"inputs\": 64, \"targets\": 2},\n",
        "    batch_size=128,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Load dataset info from drive/My Drive/MLLU/finalProject/data/super_glue/copa/1.0.2\n",
            "INFO:absl:Reusing dataset super_glue (drive/My Drive/MLLU/finalProject/data/super_glue/copa/1.0.2)\n",
            "INFO:absl:Constructing tf.data.Dataset for split validation, from drive/My Drive/MLLU/finalProject/data/super_glue/copa/1.0.2\n",
            "INFO:absl:eval/copa_new/accuracy at step 0: 0.000\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-HpwWQ97e0w",
        "colab_type": "code",
        "outputId": "aff2f5b1-f7cf-4cac-8ab5-66d5b077bb79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "# Run 2000 steps of fine-tuning\n",
        "model.train(\n",
        "    mixture_or_task_name=\"copa_new\",\n",
        "    steps=2000,\n",
        "    save_steps=200,\n",
        "    sequence_length={\"inputs\": 64, \"targets\": 2},\n",
        "    split=\"train\",\n",
        "    batch_size=32,\n",
        "    optimizer=functools.partial(transformers.AdamW, lr=1e-4),\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Load dataset info from drive/My Drive/MLLU/finalProject/data/super_glue/copa/1.0.2\n",
            "INFO:absl:Reusing dataset super_glue (drive/My Drive/MLLU/finalProject/data/super_glue/copa/1.0.2)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train, from drive/My Drive/MLLU/finalProject/data/super_glue/copa/1.0.2\n",
            "INFO:absl:Saving checkpoint for step 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-1cf7a214b0ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/t5/models/hf_model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, mixture_or_task_name, steps, save_steps, sequence_length, split, batch_size, optimizer, learning_rate_scheduler)\u001b[0m\n\u001b[1;32m    326\u001b[0m           \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inputs_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m           \u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"targets_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m           \u001b[0mlm_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"targets\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m       )\n\u001b[1;32m    330\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1cTdgrN7izL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate after fine-tuning\n",
        "model.eval(\n",
        "    \"copa_new\",\n",
        "    checkpoint_steps=\"all\",\n",
        "    sequence_length={\"inputs\": 64, \"targets\": 2},\n",
        "    batch_size=32,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sabPxKAJMdo6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluate results again\n",
        "f = open(PREDICTION_DIR + \"/validation_eval/copa_new_2000_predictions\", \"r\") \n",
        "lines = f.readlines()\n",
        "f.close()\n",
        "predicts = [line.rstrip() for line in lines]\n",
        "\n",
        "f = open(PREDICTION_DIR + \"/validation_eval/copa_new_targets\", \"r\") \n",
        "lines = f.readlines()\n",
        "f.close()\n",
        "targets = [line.rstrip() for line in lines]\n",
        "print('len:', len(predicts), len(targets))\n",
        "print('predicts:', predicts)\n",
        "print('targets:', targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc0b3HiLNOpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score = t5.evaluation.metrics.accuracy(targets, predicts)\n",
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6jEz1R3NPz6",
        "colab_type": "text"
      },
      "source": [
        "**END**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oOWoeUE9DH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}